{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b24444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d63b728",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test,y_test)=tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5c2fb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e31d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bcc9132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f781533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img):\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY )\n",
    "    img=img/255\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4833255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(list(map(preprocessing,x_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "711c42ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.array(list(map(preprocessing,x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b34a2124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f90abd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=x_train.reshape(50000,32,32,1)\n",
    "x_test=x_test.reshape(10000,32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57f2f64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4177678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2d25cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff730e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b5757b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ff7ab97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50a8e9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a72d4135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Flatten,Conv2D,MaxPooling2D,Dropout,BatchNormalization\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "669d0729",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(64,(3,3),padding=\"same\",activation=\"relu\",input_shape=(32,32,1)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(128,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(512,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128,activation=\"relu\"))\n",
    "model.add(Dense(10,activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2c4d260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f6708eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(learning_rate=0.0033),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ef380542",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "24d19710",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "   2/1563 [..............................] - ETA: 1:50 - loss: 3.1101 - accuracy: 0.0703"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tensorenv/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:3503: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 963/1563 [=================>............] - ETA: 38s - loss: 2.2718 - accuracy: 0.1911"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 22:12:55.097906: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 960).\n",
      "2022-01-10 22:12:55.098204: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 960).\n",
      "2022-01-10 22:12:55.098462: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 960).\n",
      "2022-01-10 22:12:55.098697: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 960).\n",
      "2022-01-10 22:12:55.099125: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 960).\n",
      "2022-01-10 22:12:55.100098: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 960).\n",
      "2022-01-10 22:12:55.100737: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 960).\n",
      "2022-01-10 22:12:55.102493: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 960).\n",
      "2022-01-10 22:12:55.103241: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 960).\n",
      "2022-01-10 22:12:55.103524: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 960).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 966/1563 [=================>............] - ETA: 38s - loss: 2.2710 - accuracy: 0.1913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 22:12:55.361090: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 964).\n",
      "2022-01-10 22:12:55.361330: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 964).\n",
      "2022-01-10 22:12:55.361588: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 964).\n",
      "2022-01-10 22:12:55.361796: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 964).\n",
      "2022-01-10 22:12:55.362223: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 964).\n",
      "2022-01-10 22:12:55.363178: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 964).\n",
      "2022-01-10 22:12:55.363822: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 964).\n",
      "2022-01-10 22:12:55.365566: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 964).\n",
      "2022-01-10 22:12:55.365976: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 964).\n",
      "2022-01-10 22:12:55.366272: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 964).\n",
      "2022-01-10 22:12:55.494507: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 966).\n",
      "2022-01-10 22:12:55.494727: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 966).\n",
      "2022-01-10 22:12:55.494993: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 966).\n",
      "2022-01-10 22:12:55.495215: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 966).\n",
      "2022-01-10 22:12:55.495665: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 966).\n",
      "2022-01-10 22:12:55.496632: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 966).\n",
      "2022-01-10 22:12:55.497279: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 966).\n",
      "2022-01-10 22:12:55.499075: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 966).\n",
      "2022-01-10 22:12:55.499858: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 966).\n",
      "2022-01-10 22:12:55.500093: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 966).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 970/1563 [=================>............] - ETA: 38s - loss: 2.2699 - accuracy: 0.1915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 22:12:55.630451: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 968).\n",
      "2022-01-10 22:12:55.630676: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 968).\n",
      "2022-01-10 22:12:55.630956: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 968).\n",
      "2022-01-10 22:12:55.631217: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 968).\n",
      "2022-01-10 22:12:55.631658: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 968).\n",
      "2022-01-10 22:12:55.632677: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 968).\n",
      "2022-01-10 22:12:55.633313: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 968).\n",
      "2022-01-10 22:12:55.635040: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 968).\n",
      "2022-01-10 22:12:55.635713: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 968).\n",
      "2022-01-10 22:12:55.636003: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 968).\n",
      "2022-01-10 22:12:55.698123: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 969).\n",
      "2022-01-10 22:12:55.698349: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 969).\n",
      "2022-01-10 22:12:55.698620: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 969).\n",
      "2022-01-10 22:12:55.698875: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 969).\n",
      "2022-01-10 22:12:55.699310: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 969).\n",
      "2022-01-10 22:12:55.700282: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 969).\n",
      "2022-01-10 22:12:55.700916: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 969).\n",
      "2022-01-10 22:12:55.702657: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 969).\n",
      "2022-01-10 22:12:55.703094: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 969).\n",
      "2022-01-10 22:12:55.703369: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 969).\n",
      "2022-01-10 22:12:55.828562: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 971).\n",
      "2022-01-10 22:12:55.828817: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 971).\n",
      "2022-01-10 22:12:55.829079: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 971).\n",
      "2022-01-10 22:12:55.829311: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 971).\n",
      "2022-01-10 22:12:55.829776: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 971).\n",
      "2022-01-10 22:12:55.830792: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 971).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 973/1563 [=================>............] - ETA: 38s - loss: 2.2691 - accuracy: 0.1917"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 22:12:55.831695: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 971).\n",
      "2022-01-10 22:12:55.833550: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 971).\n",
      "2022-01-10 22:12:55.834208: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 971).\n",
      "2022-01-10 22:12:55.834486: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 971).\n",
      "2022-01-10 22:12:55.898265: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 972).\n",
      "2022-01-10 22:12:55.898479: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 972).\n",
      "2022-01-10 22:12:55.898747: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 972).\n",
      "2022-01-10 22:12:55.898998: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 972).\n",
      "2022-01-10 22:12:55.899425: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 972).\n",
      "2022-01-10 22:12:55.900416: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 972).\n",
      "2022-01-10 22:12:55.901060: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 972).\n",
      "2022-01-10 22:12:55.902785: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 972).\n",
      "2022-01-10 22:12:55.903201: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 972).\n",
      "2022-01-10 22:12:55.903493: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 972).\n",
      "2022-01-10 22:12:55.965142: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 973).\n",
      "2022-01-10 22:12:55.965354: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 973).\n",
      "2022-01-10 22:12:55.965620: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 973).\n",
      "2022-01-10 22:12:55.965856: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 973).\n",
      "2022-01-10 22:12:55.966282: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 973).\n",
      "2022-01-10 22:12:55.967263: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 973).\n",
      "2022-01-10 22:12:55.967913: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 973).\n",
      "2022-01-10 22:12:55.969644: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 973).\n",
      "2022-01-10 22:12:55.970076: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 973).\n",
      "2022-01-10 22:12:55.970381: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 973).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 977/1563 [=================>............] - ETA: 38s - loss: 2.2680 - accuracy: 0.1919"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 22:12:56.100170: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 975).\n",
      "2022-01-10 22:12:56.100388: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 975).\n",
      "2022-01-10 22:12:56.100631: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 975).\n",
      "2022-01-10 22:12:56.100911: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 975).\n",
      "2022-01-10 22:12:56.101332: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 975).\n",
      "2022-01-10 22:12:56.102330: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 975).\n",
      "2022-01-10 22:12:56.102986: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 975).\n",
      "2022-01-10 22:12:56.104753: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 975).\n",
      "2022-01-10 22:12:56.105444: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 975).\n",
      "2022-01-10 22:12:56.105744: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 975).\n",
      "2022-01-10 22:12:56.166724: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 976).\n",
      "2022-01-10 22:12:56.166949: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 976).\n",
      "2022-01-10 22:12:56.167211: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 976).\n",
      "2022-01-10 22:12:56.167421: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 976).\n",
      "2022-01-10 22:12:56.167844: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 976).\n",
      "2022-01-10 22:12:56.168830: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 976).\n",
      "2022-01-10 22:12:56.169479: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 976).\n",
      "2022-01-10 22:12:56.171206: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 976).\n",
      "2022-01-10 22:12:56.172002: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 976).\n",
      "2022-01-10 22:12:56.172301: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 976).\n",
      "2022-01-10 22:12:56.232611: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 977).\n",
      "2022-01-10 22:12:56.232827: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 977).\n",
      "2022-01-10 22:12:56.233064: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 977).\n",
      "2022-01-10 22:12:56.233316: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 977).\n",
      "2022-01-10 22:12:56.233742: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 977).\n",
      "2022-01-10 22:12:56.234714: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 977).\n",
      "2022-01-10 22:12:56.235363: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 977).\n",
      "2022-01-10 22:12:56.237136: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 977).\n",
      "2022-01-10 22:12:56.237576: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 977).\n",
      "2022-01-10 22:12:56.237852: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 977).\n",
      "2022-01-10 22:12:56.297103: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 978).\n",
      "2022-01-10 22:12:56.297308: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 978).\n",
      "2022-01-10 22:12:56.297540: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 978).\n",
      "2022-01-10 22:12:56.297783: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 978).\n",
      "2022-01-10 22:12:56.298218: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 978).\n",
      "2022-01-10 22:12:56.299193: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 978).\n",
      "2022-01-10 22:12:56.299845: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 978).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 980/1563 [=================>............] - ETA: 37s - loss: 2.2672 - accuracy: 0.1920"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 22:12:56.301705: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 978).\n",
      "2022-01-10 22:12:56.302147: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 978).\n",
      "2022-01-10 22:12:56.302440: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 978).\n",
      "2022-01-10 22:12:56.365108: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 979).\n",
      "2022-01-10 22:12:56.365313: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 979).\n",
      "2022-01-10 22:12:56.365550: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 979).\n",
      "2022-01-10 22:12:56.365796: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 979).\n",
      "2022-01-10 22:12:56.366322: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 979).\n",
      "2022-01-10 22:12:56.367416: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 979).\n",
      "2022-01-10 22:12:56.368113: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 979).\n",
      "2022-01-10 22:12:56.370205: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 979).\n",
      "2022-01-10 22:12:56.370606: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 979).\n",
      "2022-01-10 22:12:56.370893: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 979).\n",
      "2022-01-10 22:12:56.496957: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 981).\n",
      "2022-01-10 22:12:56.497174: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 981).\n",
      "2022-01-10 22:12:56.497442: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 981).\n",
      "2022-01-10 22:12:56.497679: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 981).\n",
      "2022-01-10 22:12:56.498107: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 981).\n",
      "2022-01-10 22:12:56.499069: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 981).\n",
      "2022-01-10 22:12:56.499691: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 981).\n",
      "2022-01-10 22:12:56.501424: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 981).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 983/1563 [=================>............] - ETA: 37s - loss: 2.2664 - accuracy: 0.1922"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 22:12:56.501848: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 981).\n",
      "2022-01-10 22:12:56.502234: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 981).\n",
      "2022-01-10 22:12:56.565881: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 982).\n",
      "2022-01-10 22:12:56.566100: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 982).\n",
      "2022-01-10 22:12:56.566332: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 982).\n",
      "2022-01-10 22:12:56.566574: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 982).\n",
      "2022-01-10 22:12:56.567007: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 982).\n",
      "2022-01-10 22:12:56.567971: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 982).\n",
      "2022-01-10 22:12:56.568588: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 982).\n",
      "2022-01-10 22:12:56.570345: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 982).\n",
      "2022-01-10 22:12:56.570768: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 982).\n",
      "2022-01-10 22:12:56.571055: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 982).\n",
      "2022-01-10 22:12:56.632306: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 983).\n",
      "2022-01-10 22:12:56.632558: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 983).\n",
      "2022-01-10 22:12:56.632826: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 983).\n",
      "2022-01-10 22:12:56.633062: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 983).\n",
      "2022-01-10 22:12:56.633489: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 983).\n",
      "2022-01-10 22:12:56.634436: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 983).\n",
      "2022-01-10 22:12:56.635086: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 983).\n",
      "2022-01-10 22:12:56.636847: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 983).\n",
      "2022-01-10 22:12:56.637266: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 983).\n",
      "2022-01-10 22:12:56.637537: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 983).\n",
      "2022-01-10 22:12:56.697491: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 984).\n",
      "2022-01-10 22:12:56.697738: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 984).\n",
      "2022-01-10 22:12:56.698001: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 984).\n",
      "2022-01-10 22:12:56.698228: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 984).\n",
      "2022-01-10 22:12:56.698652: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 984).\n",
      "2022-01-10 22:12:56.699601: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 984).\n",
      "2022-01-10 22:12:56.700245: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 984).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 987/1563 [=================>............] - ETA: 37s - loss: 2.2654 - accuracy: 0.1924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-10 22:12:56.702310: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 984).\n",
      "2022-01-10 22:12:56.702823: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 984).\n",
      "2022-01-10 22:12:56.703206: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 984).\n",
      "2022-01-10 22:12:56.765648: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 985).\n",
      "2022-01-10 22:12:56.765880: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 985).\n",
      "2022-01-10 22:12:56.766137: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 985).\n",
      "2022-01-10 22:12:56.766409: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 985).\n",
      "2022-01-10 22:12:56.766857: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 985).\n",
      "2022-01-10 22:12:56.767916: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 985).\n",
      "2022-01-10 22:12:56.768588: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 985).\n",
      "2022-01-10 22:12:56.770360: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 985).\n",
      "2022-01-10 22:12:56.771095: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 985).\n",
      "2022-01-10 22:12:56.771374: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 985).\n",
      "2022-01-10 22:12:56.831862: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 986).\n",
      "2022-01-10 22:12:56.832079: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 986).\n",
      "2022-01-10 22:12:56.832313: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 986).\n",
      "2022-01-10 22:12:56.832566: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 986).\n",
      "2022-01-10 22:12:56.833014: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 986).\n",
      "2022-01-10 22:12:56.833975: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 986).\n",
      "2022-01-10 22:12:56.834589: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 986).\n",
      "2022-01-10 22:12:56.836680: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 986).\n",
      "2022-01-10 22:12:56.837098: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 986).\n",
      "2022-01-10 22:12:56.837387: W tensorflow/compiler/tf2mlcompute/convert/mlc_convert_utils.cc:690] ComputeTimeStepForAdam: Computing time_step from beta1_power and beta2_power gives different results, probably due to losing precision in pow or log. The time_step that comes from the larger beta_power is chosen (time_step = 986).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 102s 65ms/step - loss: 2.1470 - accuracy: 0.2193\n",
      "Epoch 2/40\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 1.5238 - accuracy: 0.4352\n",
      "Epoch 3/40\n",
      "1563/1563 [==============================] - 101s 65ms/step - loss: 1.1725 - accuracy: 0.5878\n",
      "Epoch 4/40\n",
      "1563/1563 [==============================] - 109s 69ms/step - loss: 0.9677 - accuracy: 0.6712\n",
      "Epoch 5/40\n",
      "1563/1563 [==============================] - 101s 65ms/step - loss: 0.8342 - accuracy: 0.7185\n",
      "Epoch 6/40\n",
      "1563/1563 [==============================] - 101s 65ms/step - loss: 0.7571 - accuracy: 0.7465\n",
      "Epoch 7/40\n",
      "1563/1563 [==============================] - 101s 65ms/step - loss: 0.6870 - accuracy: 0.7695\n",
      "Epoch 8/40\n",
      "1563/1563 [==============================] - 101s 65ms/step - loss: 0.6125 - accuracy: 0.7949\n",
      "Epoch 9/40\n",
      "1563/1563 [==============================] - 101s 65ms/step - loss: 0.5464 - accuracy: 0.8183\n",
      "Epoch 10/40\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.5068 - accuracy: 0.8352\n",
      "Epoch 11/40\n",
      "1563/1563 [==============================] - 105s 67ms/step - loss: 0.4557 - accuracy: 0.8510\n",
      "Epoch 12/40\n",
      "1563/1563 [==============================] - 105s 67ms/step - loss: 0.4261 - accuracy: 0.8615\n",
      "Epoch 13/40\n",
      "1563/1563 [==============================] - 105s 67ms/step - loss: 0.3834 - accuracy: 0.8764\n",
      "Epoch 14/40\n",
      "1563/1563 [==============================] - 123s 78ms/step - loss: 0.3786 - accuracy: 0.8778\n",
      "Epoch 15/40\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.3395 - accuracy: 0.8911\n",
      "Epoch 16/40\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.3054 - accuracy: 0.9014\n",
      "Epoch 17/40\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.3151 - accuracy: 0.9012\n",
      "Epoch 18/40\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.2948 - accuracy: 0.9076\n",
      "Epoch 19/40\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.2798 - accuracy: 0.9109\n",
      "Epoch 20/40\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.2661 - accuracy: 0.9160\n",
      "Epoch 21/40\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 0.2817 - accuracy: 0.9137\n",
      "Epoch 22/40\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.2327 - accuracy: 0.9294\n",
      "Epoch 23/40\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.2549 - accuracy: 0.9245\n",
      "Epoch 24/40\n",
      "1563/1563 [==============================] - 105s 67ms/step - loss: 0.2089 - accuracy: 0.9372\n",
      "Epoch 25/40\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.2155 - accuracy: 0.9348\n",
      "Epoch 26/40\n",
      "1563/1563 [==============================] - 102s 66ms/step - loss: 0.2765 - accuracy: 0.9193\n",
      "Epoch 27/40\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.2000 - accuracy: 0.9407\n",
      "Epoch 28/40\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.2683 - accuracy: 0.9233\n",
      "Epoch 29/40\n",
      "1563/1563 [==============================] - 102s 66ms/step - loss: 0.2034 - accuracy: 0.9412\n",
      "Epoch 30/40\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.1777 - accuracy: 0.9479\n",
      "Epoch 31/40\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.2559 - accuracy: 0.9321\n",
      "Epoch 32/40\n",
      "1563/1563 [==============================] - 102s 66ms/step - loss: 0.1979 - accuracy: 0.9421\n",
      "Epoch 33/40\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.1967 - accuracy: 0.9421\n",
      "Epoch 34/40\n",
      "1563/1563 [==============================] - 104s 66ms/step - loss: 0.1882 - accuracy: 0.9459\n",
      "Epoch 35/40\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.1844 - accuracy: 0.9487\n",
      "Epoch 36/40\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.1854 - accuracy: 0.9480\n",
      "Epoch 37/40\n",
      "1563/1563 [==============================] - 103s 66ms/step - loss: 0.1868 - accuracy: 0.9472\n",
      "Epoch 38/40\n",
      "1563/1563 [==============================] - 104s 66ms/step - loss: 0.2665 - accuracy: 0.9264\n",
      "Epoch 39/40\n",
      "1563/1563 [==============================] - 105s 67ms/step - loss: 0.2055 - accuracy: 0.9447\n",
      "Epoch 40/40\n",
      "1563/1563 [==============================] - 105s 67ms/step - loss: 0.1691 - accuracy: 0.9540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16256ff40>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "9aad3c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy->  95.4\n"
     ]
    }
   ],
   "source": [
    "print(\"training accuracy-> \",95.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "160292ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_in_json=model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1206de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"/Users/akshaykumar/Documents/ml/dataset_best.json\",\"w\")\n",
    "file.write(model_in_json)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ca16a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"/Users/akshaykumar/Documents/ml/weights_best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f76adf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5fe9eb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "3be55fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(\"/Users/akshaykumar/Documents/ml/dataset_best.json\",\"r\")\n",
    "loaded_data=file.read()\n",
    "loaded_model=model_from_json(loaded_data)\n",
    "loaded_model.load_weights(\"/Users/akshaykumar/Documents/ml/weights_best.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5885e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=loaded_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "42540f79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "f9948e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=np.argmax(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ba65d4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1ba25a09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "caaa0dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a967e636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy=accuracy_score(y_test,pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "69178cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy-> 71.51%\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing accuracy->\",str(round(accuracy*100,2))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "bdb8758b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_117 (Conv2D)          (None, 32, 32, 64)        640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_89 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_118 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_90 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_119 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_91 (MaxPooling (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_92 (MaxPooling (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_93 (MaxPooling (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 4,077,706\n",
      "Trainable params: 4,076,426\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c4311",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorenv] *",
   "language": "python",
   "name": "conda-env-tensorenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
